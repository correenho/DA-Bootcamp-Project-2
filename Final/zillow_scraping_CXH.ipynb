{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow.com scraping for property details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the splinter browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up browser to zillow.com\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = 'https://www.zillow.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for Torrance\n",
    "search_bar_xpath ='//*[@id=\"search-box-input\"]'\n",
    "search_bar = browser.find_by_xpath(search_bar_xpath)[0]\n",
    "\n",
    "search_bar.clear()\n",
    "search_bar.fill('Long Beach, CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button_xpath = '//*[@id=\"search-bar\"]/div/div/form/div/div[1]/label' \n",
    "search_button = browser.find_by_xpath(search_button_xpath)[0] \n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grabbing the Buy Address List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select \"For Buy\"\n",
    "buy_button_xpath = '/html/body/div[9]/div/div[1]/div/div/div/ul/li[1]/button' \n",
    "buy_button = browser.find_by_xpath(buy_button_xpath)\n",
    "buy_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 1 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4208+Tulane+Ave', '1582+W+31st+St', '3615+Faust+Ave', '1312+E+Luray+St', '5615+Dairy+Ave', '1844+E+65th+St', '1701+Orizaba+Ave', '2631+Daisy+Ave', '100+Atlantic+Ave+APT+811', '6831+E+Septimo+St', '63+Pomona+Ave', '4550+Graywood+Ave', '115+E+59th+St', '5455+Dairy+Ave', '3763+Faust+Ave', '1450+Locust+Ave+APT+123', '6274+E+Marina+View+Dr+#+318', '5436+E+The+Toledo', '4724+Montair+Ave', '640+W+4th+St+UNIT+314', '1730+Lemon+Ave', '3772+Albury+Ave', '1770+Ximeno+Ave+APT+206', '3008+Shadypark+Dr', '4738+Pearce+Ave', '215+E+Ellis+St', '2946+Gale+Ave', '100+Atlantic+Ave+APT+612', '7040+E+Mezzanine+Way', '504+Nebraska+Ave', '4774+E+Malta+St+APT+1', '3603+Ostrom+Ave', '5150+E+Wardlow+Rd', '20+37th+Pl', '2840+E+10th+St', '6425+Orizaba+Ave', '1517+E+16th+St', '5203+E+Spring+St', '4219+E+6th+St', '1171+Bryant+Rd', '2160+Pine+Ave', '85+Prospect+Ave'] ['$1,423,500', '$649,999', '$849,000', '$659,000', '$439,000', '$475,000', '$449,000', '$450,000', '$250,000', '$879,900', '$1,600,000', '$1,129,000', '$575,000', '$469,900', '$724,900', '$179,900', '$304,999', '$6,400,000', '$699,990', '$315,000', '$485,000', '$915,000', '$400,000', '$825,000', '$565,000', '$550,000', '$559,900', '$418,000', '$1,195,000', '$525,000', '$549,900', '$784,900', '$658,000', '$10,995,000', '$615,000', '$639,900', '$369,000', '$689,000', '$995,000', '$2,595,000', '$620,000', '$1,079,900'] ['5 bds 4 ba 3,850 sqft', '5 bds 3 ba 2,209 sqft', '3 bds 2 ba 1,664 sqft', '4 bds 2 ba 1,836 sqft', '3 bds 1 ba 956 sqft', '2 bds 1 ba 1,260 sqft', '3 bds 2 ba 892 sqft', '2 bds 1 ba 1,112 sqft', 'Studio1 ba 490 sqft', '4 bds 2 ba 1,626 sqft', '3 bds 3 ba 2,119 sqft', '4 bds 3 ba 2,700 sqft', '3 bds 2 ba 1,621 sqft', '2 bds 1 ba 640 sqft', '3 bds 2 ba 1,807 sqft', '1 bd1 ba 471 sqft', '2 bds 2 ba 1,350 sqft', '4 bds 4 ba 4,622 sqft', '3 bds 2 ba 1,432 sqft', '1 bd1 ba 622 sqft', '3 bds 2 ba 1,286 sqft', '6 bds 4 ba 2,700 sqft', '2 bds 2 ba 1,076 sqft', '5 bds 2 ba 2,104 sqft', '2 bds 1 ba 888 sqft', '3 bds 2 ba 1,474 sqft', '3 bds 3 ba 1,666 sqft', '2 bds 1 ba 730 sqft', '4 bds 2 ba 2,055 sqft', '2 bds 2 ba 830 sqft', '3 bds 3 ba 1,660 sqft', '3 bds 2 ba 1,659 sqft', '4 bds 2 ba 1,604 sqft', '3 bds 6 ba 7,692 sqft', '2 bds 2 ba 1,119 sqft', '3 bds 2 ba 1,463 sqft', '1 bd1 ba 582 sqft', '3 bds 2 ba 1,130 sqft', '4 bds 3 ba 2,013 sqft', '5 bds 4 ba 4,134 sqft', '4 bds 2 ba 2,144 sqft', '3 bds 1 ba 1,390 sqft']\n"
     ]
    }
   ],
   "source": [
    "#Grab the first page of results and store them\n",
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_1=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_1.append(api_add)\n",
    "\n",
    "\n",
    "buy_price_list_1 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_1.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_1 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_1.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "        \n",
    "print(f\"{buy_address_list_1} {buy_price_list_1} {buy_details_list_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4208+Tulane+Ave', '1582+W+31st+St', '3615+Faust+Ave', '1312+E+Luray+St', '5615+Dairy+Ave', '1844+E+65th+St', '1701+Orizaba+Ave', '2631+Daisy+Ave', '100+Atlantic+Ave+APT+811', '6831+E+Septimo+St', '63+Pomona+Ave', '4550+Graywood+Ave', '115+E+59th+St', '5455+Dairy+Ave', '3763+Faust+Ave', '1450+Locust+Ave+APT+123', '6274+E+Marina+View+Dr+#+318', '5436+E+The+Toledo', '4724+Montair+Ave', '640+W+4th+St+UNIT+314', '1730+Lemon+Ave', '3772+Albury+Ave', '1770+Ximeno+Ave+APT+206', '3008+Shadypark+Dr', '4738+Pearce+Ave', '215+E+Ellis+St', '2946+Gale+Ave', '100+Atlantic+Ave+APT+612', '7040+E+Mezzanine+Way', '504+Nebraska+Ave', '4774+E+Malta+St+APT+1', '3603+Ostrom+Ave', '5150+E+Wardlow+Rd', '20+37th+Pl', '2840+E+10th+St', '6425+Orizaba+Ave', '1517+E+16th+St', '5203+E+Spring+St', '4219+E+6th+St', '1171+Bryant+Rd', '2160+Pine+Ave', '85+Prospect+Ave'] ['$1,423,500', '$649,999', '$849,000', '$659,000', '$439,000', '$475,000', '$449,000', '$450,000', '$250,000', '$879,900', '$1,600,000', '$1,129,000', '$575,000', '$469,900', '$724,900', '$179,900', '$304,999', '$6,400,000', '$699,990', '$315,000', '$485,000', '$915,000', '$400,000', '$825,000', '$565,000', '$550,000', '$559,900', '$418,000', '$1,195,000', '$525,000', '$549,900', '$784,900', '$658,000', '$10,995,000', '$615,000', '$639,900', '$369,000', '$689,000', '$995,000', '$2,595,000', '$620,000', '$1,079,900'] ['5 bds 4 ba 3,850 sqft', '5 bds 3 ba 2,209 sqft', '3 bds 2 ba 1,664 sqft', '4 bds 2 ba 1,836 sqft', '3 bds 1 ba 956 sqft', '2 bds 1 ba 1,260 sqft', '3 bds 2 ba 892 sqft', '2 bds 1 ba 1,112 sqft', 'Studio1 ba 490 sqft', '4 bds 2 ba 1,626 sqft', '3 bds 3 ba 2,119 sqft', '4 bds 3 ba 2,700 sqft', '3 bds 2 ba 1,621 sqft', '2 bds 1 ba 640 sqft', '3 bds 2 ba 1,807 sqft', '1 bd1 ba 471 sqft', '2 bds 2 ba 1,350 sqft', '4 bds 4 ba 4,622 sqft', '3 bds 2 ba 1,432 sqft', '1 bd1 ba 622 sqft', '3 bds 2 ba 1,286 sqft', '6 bds 4 ba 2,700 sqft', '2 bds 2 ba 1,076 sqft', '5 bds 2 ba 2,104 sqft', '2 bds 1 ba 888 sqft', '3 bds 2 ba 1,474 sqft', '3 bds 3 ba 1,666 sqft', '2 bds 1 ba 730 sqft', '4 bds 2 ba 2,055 sqft', '2 bds 2 ba 830 sqft', '3 bds 3 ba 1,660 sqft', '3 bds 2 ba 1,659 sqft', '4 bds 2 ba 1,604 sqft', '3 bds 6 ba 7,692 sqft', '2 bds 2 ba 1,119 sqft', '3 bds 2 ba 1,463 sqft', '1 bd1 ba 582 sqft', '3 bds 2 ba 1,130 sqft', '4 bds 3 ba 2,013 sqft', '5 bds 4 ba 4,134 sqft', '4 bds 2 ba 2,144 sqft', '3 bds 1 ba 1,390 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_2=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_2.append(api_add)\n",
    "\n",
    "\n",
    "buy_price_list_2 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_2.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "\n",
    "buy_details_list_2 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_2.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_2=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_2.append(api_add)\n",
    "\n",
    "\n",
    "buy_price_list_2 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_2.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_2 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_2.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_4=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_4.append(api_add)\n",
    "\n",
    "\n",
    "buy_price_list_4 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_4.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_4 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_4.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[10]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_5=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_5.append(api_add)\n",
    "\n",
    "\n",
    "buy_price_list_5 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_5.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_5 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_5.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_6=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_6.append(api_add)\n",
    "\n",
    "\n",
    "buy_price_list_6 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_6.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_6 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_6.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['208+Nieto+Ave', '2601+E+Ocean+Blvd+UNIT+110', '2234+E+Spaulding+St', '3595+Santa+Fe+Ave+#12', '1071+E+Chanda+Ct', '1090+Martin+Luther+King+Jr+Ave', '3537+Falcon+Ave', '4833+Blackthorne+Ave', '488+E+Ocean+Blvd+UNIT+418', '6475+Atlantic+Ave+SPC+274', '6263+E+Golden+Sands+Dr', '2100+Earl+Ave', '1901+E+Ocean+Blvd+UNIT+206', '700+E+Ocean+Blvd+UNIT+2602', '3595+Santa+Fe+Ave+SPC+85', '3738+Albury+Ave', '1400+E+Ocean+Blvd+UNIT+1305', '1701+E+1st+St', '6932+E+El+Roble+St', '3913+N+Virginia+Rd+UNIT+107', '323+W+4th+St+APT+406', '1140+E+Ocean+Blvd+UNIT+233', '6237+Beachcomber+Dr+#+109', '138+Rivo+Alto+Canal', '1480+Martin+Luther+King+Jr+Ave', '7101+Eastondale+Ave', '21+7th+Pl+APT+408', '4553+N+Deal+Dr', '4113+E+10th+St+APT+3', '2828+Ladoga+Ave', '2322+Roswell+Ave', '835+Locust+Ave+UNIT+410', '6216+E+Emerald+Cove+Dr+#+47', '436+N+Bellflower+Blvd+UNIT+204', '2910+De+Forest+Ave', '1052+E+Andrews+Dr', '800+E+Ocean+Blvd+UNIT+709', '6300+Riviera+Cir', '9+Rivo+Alto+Canal', '535+E+14th+St'], ['$1,049,900', '$469,000', '$800,000', '$359,000', 'Est. $478,870', '$668,000', '$687,038', '$646,638', '$538,000', '$80,000', '$187,000', '$1,300,000', '$685,000', '$645,995', '$509,000', '$595,797', '$1,345,000', '$1,380,000', 'Est. $710,926', '$498,000', '$219,500', '$489,000', '$225,000', '$1,995,000', '$469,990', '$585,000', '$725,000', 'Est. $520,807', 'Est. $349,546', '$--', '$819,999', '$554,000', '$189,000', '$375,000', '$649,999', 'Est. $1,061,771', '$460,000', '$725,000', '$2,549,000', '$850,000'], ['2 bds 2 ba 1,140 sqft', '1 bd1 ba 672 sqft', '6 bds 3 ba 1,825 sqft', '2 bds 2 ba 1,900 sqft', '3 bds 2.5 ba 1,082 sqft', '3 bds 3 ba 1,584 sqft', '4 bds 2 ba 1,636 sqft', '3 bds 2 ba 1,091 sqft', '2 bds 2 ba 960 sqft', '3 bds 1 ba -- sqft', '2 bds 2 ba 1,344 sqft', '9 bds 8 ba 3,620 sqft', '2 bds 3 ba 1,544 sqft', '2 bds 2 ba 1,080 sqft', '4 bds 2 ba 1,600 sqft', '2 bds 1 ba 808 sqft', '3 bds 2 ba 1,259 sqft', '6 bds 4 ba 2,744 sqft', '3 bds 2 ba 1,039 sqft', '2 bds 2 ba 1,070 sqft', 'Studio1 ba 370 sqft', '1 bd1 ba 732 sqft', '2 bds 2 ba 1,200 sqft', '2 bds 2 ba 1,738 sqft', '2 bds 1 ba 960 sqft', '5 bds 3 ba 1,875 sqft', '2 bds 2 ba 1,355 sqft', '3 bds 1 ba 1,133 sqft', '2 bds 2 ba 740 sqft', '2 bds 1 ba 1,150 sqft', '3 bds 3 ba 2,057 sqft', '1 bd1 ba 989 sqft', '2 bds 2 ba 1,120 sqft', '1 bd1 ba 693 sqft', '3 bds 2 ba 1,473 sqft', '3 bds 3 ba 3,341 sqft', '1 bd1 ba 872 sqft', '3 bds 2 ba 1,715 sqft', '3 bds 3 ba 2,184 sqft', '4 bds 2 ba 2,291 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_7=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_7.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_7 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_7.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_7 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_7.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6109+Lime+Ave', '5640+Azure+Way', '3595+Santa+Fe+Ave+#+100', '2400+E+5th+St', '2717+Radnor+Ave', '6475+Atlantic+Ave+SPC+344', '395+E+4th+St+UNIT+6', '1310+E+Ocean+Blvd+UNIT+705', '5585+E+Pacific+Coast+Hwy+UNIT+218', '488+E+Ocean+Blvd+UNIT+610', '3939+E+Allin+St+UNIT+205', '3939+Walnut+Ave', '2211+Conquista+Ave', '6257+E+Emerald+Cove+Dr', '3295+Adriatic+Ave', '835+Locust+Ave+UNIT+111', '6665+Long+Beach+Blvd+SPC+B19', '6475+Atlantic+Ave+SPC+715', '42+62nd+Pl', '646+Coronado+Ave+APT+B', '300+Manila+Ave', '2331+Snowden+Ave', '1487+Henderson+Ave', '380+Wisconsin+Ave', '455+E+Ocean+Blvd+APT+605', '18+E+56th+St', '3707+Country+Club+Dr+UNIT+3', '5272+Pine+Ave', '1750+E+Ocean+Blvd+UNIT+1605', '850+E+Ocean+Blvd+UNIT+1501', '6523+E+Monlaco+Rd', '1521+Locust+Ave+APT+14', '512+Almond+Ave', '8018+Dorado+Cir', '5571+E+Monlaco+Rd', '1993+Lemon+Ave', '2481+Terraine+Ave', '40+Belmont+Ave', '4920+Brook+Ave', '1+3rd+Pl+UNIT+805'], ['$575,000', '$1,399,000', '$484,000', '$1,300,000', 'Est. $669,350', '$80,000', '$479,000', '$685,000', '$285,000', '$610,000', '$425,900', '$829,451', '$--', '$129,900', '$825,000', '$480,000', '$60,000', '$69,000', '$1,250,000', '$597,600', '$1,209,000', '$599,000', '$1,025,000', '$875,000', '$310,000', '$1,075,000', '$428,000', '$385,000', '$920,000', '$660,000', '$--', '$359,000', '$799,000', '$929,990', 'Est. $629,002', 'Est. $388,223', '$1,100,000', '$1,850,000', '$50,000', '$799,000'], ['2 bds 2 ba 1,504 sqft', '3 bds 3 ba 1,600 sqft', '4 bds 2 ba 1,687 sqft', '5 bds 4 ba 3,112 sqft', '3 bds 2 ba 1,276 sqft', '4 bds 1 ba -- sqft', '1 bd1 ba 1,020 sqft', '1 bd1 ba 990 sqft', '1 bd1 ba 597 sqft', '2 bds 2 ba 990 sqft', '1 bd1 ba 740 sqft', '2 bds 3 ba 1,912 sqft', '3 bds 1 ba 1,055 sqft', '2 bds 2 ba 1,200 sqft', '7 bds 5 ba 3,171 sqft', '1 bd1 ba 791 sqft', '2 bds 1 ba 672 sqft', '2 bds 1 ba 800 sqft', '4 bds 3 ba 2,980 sqft', '3 bds 2 ba 1,200 sqft', '3 bds 4 ba 2,948 sqft', '2 bds 2 ba 1,260 sqft', '10 bds 4 ba 3,520 sqft', '3 bds 2 ba 1,739 sqft', '1 bd1 ba 421 sqft', '13 bds 5 ba 2,342 sqft', '2 bds 2 ba 956 sqft', '1 bd1 ba 607 sqft', '2 bds 2 ba 1,116 sqft', '1 bd1 ba 1,013 sqft', '4 bds 3 ba 2,056 sqft', '2 bds 2 ba 1,075 sqft', '4 bds 2 ba 1,490 sqft', '4 bds 4 ba 2,465 sqft', '2 bds 1 ba 1,204 sqft', '2 bds 1 ba 660 sqft', '5 bds 5 ba 3,058 sqft', '1 bd2 ba 2,378 sqft', '2 bds 1 ba 400 sqft', '2 bds 2 ba 1,251 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_8=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_8.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_8 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_8.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_8 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_8.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1140+E+Ocean+Blvd+UNIT+334', '3451+E+Janice+St', '2125+Pine+Ave', '388+E+Ocean+Blvd+UNIT+410', '1802+Elmfield+Ave', '326+Hermosa+Ave+APT+2', '335+E+Marker+Ln', '488+E+Ocean+Blvd+UNIT+P1', '6550+E+Espanita+St', '335+Cedar+Ave+UNIT+307', '2256+San+Anseline+Ave', '1043+E+Terrace+Dr', '784+Stanley+Ave', '4821+E+Ocean+Blvd+#+AB', '3060+Linden+Ave', '658+Coronado+Ave', '2340+Gale+Ave', '380+Panama+Ave', '2507+E+15th+St+UNIT+313', '3693+Palo+Verde+Ave', '1901+E+Ocean+Blvd+UNIT+205', '3939+E+Allin+St+UNIT+108', '1+62nd+Pl+UNIT+302', '3751+Olive+Ave', '7101+Marina+Pacifica+Dr+S', '908+Walnut+Ave', '100+Esperanza+Ave+#+4', '25+15th+Pl+UNIT+703', '6245+E+Emerald+Cove+Dr', '3595+Santa+Fe+Ave+#+101', '343+Orizaba+Ave+UNIT+C', '342+Salta+Verde+Point', '784+Redondo+Ave', '1415+E+Ocean+Blvd+APT+202', '1816+Montair+Ave', '1415+E+4th+St+APT+14', '2838+Albury+Ave', '3115+Shipway+Ave', '1444+E+Appleton+St', '6226+E+Sea+Breeze+Dr+#+80'], ['$519,000', 'Est. $589,340', '$546,999', '$599,000', 'Est. $1,019,642', '$339,000', '$560,000', '$1,075,000', 'Est. $890,111', '$265,000', '$1,815,000', 'Est. $632,603', '$1,250,000', 'Est. $1,291,304', '$1,150,000', '$1,000,000', 'Est. $626,946', 'Est. $1,994,945', '$349,900', '$732,680', '$749,000', '$429,000', '$995,000', 'Est. $656,783', '$535,000', '$725,000', 'Est. $393,134', '$780,000', '$179,000', '$524,500', 'Est. $425,665', '$2,075,888', '$--', '$799,000', 'Est. $777,413', '$379,500', 'Est. $662,987', 'Est. $927,376', 'Est. $698,780', '$63,000'], ['1 bd1 ba 732 sqft', '4 bds 2 ba 1,200 sqft', '3 bds 1 ba 1,339 sqft', '2 bds 2 ba 990 sqft', '6 bds 3 ba 2,703 sqft', '1 bd1 ba 680 sqft', '4 bds 3 ba 1,931 sqft', '3 bds 4 ba 2,285 sqft', '3 bds 2 ba 2,309 sqft', '1 bd1 ba 515 sqft', '8 bds 6 ba 4,404 sqft', '5 bds 2 ba 1,705 sqft', '6 bds 6 ba 3,156 sqft', '4 bds 3 ba 2,524 sqft', '3 bds 3 ba 2,584 sqft', '4 bds 3 ba 2,063 sqft', '6 bds 3 ba 3,200 sqft', '5 bds 5 ba 5,050 sqft', '2 bds 2 ba 842 sqft', '3 bds 3 ba 1,813 sqft', '2 bds 3 ba 1,883 sqft', '1 bd1 ba 685 sqft', '2 bds 2 ba 1,221 sqft', '2 bds 1 ba 981 sqft', '1 bd1 ba 828 sqft', '3 bds 1 ba 1,012 sqft', '2 bds 1 ba 946 sqft', '3 bds 2 ba 1,310 sqft', '2 bds 2 ba 1,440 sqft', '3 bds 2 ba 1,600 sqft', '2 bds 2 ba 901 sqft', '3 bds 3 ba 2,560 sqft', '4 bds 3 ba 3,808 sqft', '2 bds 2 ba 1,648 sqft', '3 bds 2 ba 1,641 sqft', '1 bd1 ba 731 sqft', '3 bds 2 ba 1,300 sqft', '4 bds 2 ba 1,383 sqft', '2 bds 1 ba 1,104 sqft', '2 bds 1 ba 640 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_9=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_9.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_9 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_9.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_9 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_9.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6112+Corsica+Cir', '3691+Cortner+Ave', '6207+E+Emerald+Cove+Dr+#+54', '419+E+Smith+St', '3638+E+Ocean+Blvd', '388+E+Ocean+Blvd+UNIT+402', '6260+Beachcomber+Dr+#+289', '300+E+4th+St+UNIT+407', '3910+Elm+Ave', '411+W+Seaside+Way+UNIT+903', '5530+E+Parkcrest+St', '25+15th+Pl+UNIT+705', '400+W+Ocean+Blvd+#+1404', '437+Newport+Ave', '1174+E+Ocean+Blvd+UNIT+18', '525+E+Seaside+Way+UNIT+405', '725+Coronado+Ave+UNIT+109', '525+E+Seaside+Way+UNIT+1109', '2412+Gale+Ave', '52+E+Market+St', '6226+E+Golden+Sands+Dr+#+199', '22+W+Mountain+View+St', '388+E+Ocean+Blvd+UNIT+P10', '3921+Lees+Ave', '1431+E+Hellman+St', '1750+E+Ocean+Blvd+UNIT+407', '1450+Peterson+Ave', '700+E+Ocean+Blvd+UNIT+2205', '2729+Iroquois+Ave', '3623+E+11th+St', '700+E+Ocean+Blvd+UNIT+2308', '2114+Nipomo+Ave', '1000+E+Ocean+Blvd+UNIT+305', '5723+E+Mezzanine+Way', '178+W+67th+Way', '3438+Adriatic+Ave', '1717+E+Artesia+Blvd', '388+E+Ocean+Blvd+UNIT+1601', '1358+Gundry+Ave', '10+N+Alboni+Pl+#+8'], ['$2,500,000', 'Est. $611,893', '$248,900', '$--', '$2,650,000', '$435,900', '$194,000', 'Est. $556,296', '$725,000', '$898,000', 'Est. $573,504', '$699,990', '$775,000', '$1,649,999', '$849,500', '$610,000', 'Est. $376,811', '$768,000', 'Est. $395,599', '$345,000', '$259,900', '$929,900', '$1,150,000', 'Est. $672,846', '$999,999', 'Est. $636,739', 'Est. $629,613', '$824,900', 'Est. $620,138', 'Est. $503,145', '$849,000', 'Est. $806,017', '$1,250,000', 'Est. $647,227', '$505,000', '$429,995', '$469,000', 'Est. $587,350', 'Est. $520,948', 'Est. $437,801'], ['3 bds 3 ba 2,778 sqft', '3 bds 2 ba 1,608 sqft', '2 bds 2 ba 1,447 sqft', '3 bds 1 ba 1,020 sqft', '7 bds 5 ba 4,050 sqft', '1 bd1 ba 600 sqft', '3 bds 2 ba 1,080 sqft', '2 bds 3 ba 1,340 sqft', '10,497 sqft lot', '2 bds 2 ba 1,410 sqft', '2 bds 1 ba 936 sqft', '2 bds 2 ba 990 sqft', '2 bds 2 ba 1,660 sqft', '9 bds 7 ba 4,605 sqft', '2 bds 1 ba 1,018 sqft', '2 bds 2 ba 1,218 sqft', '2 bds 2 ba 838 sqft', '2 bds 2 ba 1,313 sqft', '3 bds 1 ba 781 sqft', '1 bd1 ba 576 sqft', '2 bds 2 ba 1,456 sqft', '7 bds 4 ba 2,600 sqft', '2 bds 3 ba 1,930 sqft', '3 bds 2 ba 1,269 sqft', '7 bds 5 ba 3,411 sqft', '1 bd1 ba 853 sqft', '4 bds 2 ba 1,475 sqft', '2 bds 2 ba 1,080 sqft', '3 bds 1 ba 1,343 sqft', '2 bds 1 ba 852 sqft', '3 bds 2 ba 1,260 sqft', '4 bds 3 ba 2,253 sqft', '3 bds 2 ba 1,409 sqft', '3 bds 1 ba 1,031 sqft', '3 bds 1 ba 966 sqft', '2 bds 1 ba 819 sqft', '1 bd1 ba 1,258 sqft', '2 bds 2 ba 960 sqft', '5 bds 2 ba 1,206 sqft', '2 bds 1 ba 1,209 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_10=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_10.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_10 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_10.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_10 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_10.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "\n",
    "print(f\"{buy_address_list_10}, {buy_price_list_10}, {buy_details_list_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5431+E+29th+St', '455+E+Ocean+Blvd+APT+401', 'Ave', '1117+N+Nylic+Ct', '1171+E+Claiborne+Dr', '3452+Elm+Ave+UNIT+203', '1009+Gardenia+Ave', '1404+E+1st+St+APT+8', '2049+Orange+Ave', '3141+Chatwin+Ave', '6348+E+Marita+St', '388+E+Ocean+Blvd+UNIT+102', '2154+Pacific+Ave', '1505+Hile+Ave', '2027+E+Appleton+St+UNIT+11', '3101+E+2nd+St+UNIT+1A', '835+Locust+Ave+UNIT+323', '133+The+Promenade+N+UNIT+404', '6273+E+Emerald+Cove+Dr+#+282', '433+Pine+Ave+UNIT+301', '63+65th+Pl', '8170+E+Topia+St', '388+E+Ocean+Blvd+UNIT+301', '850+E+Ocean+Blvd+UNIT+503', '448+N+Bellflower+Blvd+UNIT+103', '847+Junipero+Ave', '433+Pine+Ave+UNIT+204', '637+E+4th+St+UNIT+A', '273+E+Del+Amo+Blvd', '6247+E+Golden+Sands+Dr+#184', '8024+Dorado+Cir', '4424+Gaviota+Ave', '1067+Stanley+Ave', '5836+E+Marita+St', '5585+E+Pacific+Coast+Hwy+UNIT+314', '3520+Kemble+Ave', '6120+Marina+Pacifica+Dr+S', '525+E+Seaside+Way+UNIT+402', '3121+Long+Beach+Blvd', '3595+Santa+Fe+Ave+#+51'], ['Est. $653,488', '$489,000', '$625,000', '$767,238', 'Est. $931,286', 'Est. $261,718', '$795,000', 'Est. $304,866', '$899,900', 'Est. $677,603', 'Est. $780,032', '$600,000', '$750,888', 'Est. $416,589', 'Est. $435,869', 'Est. $532,767', 'Est. $625,506', '$575,000', '$234,000', '$539,000', '$2,399,000', 'Est. $640,346', '$529,000', '$899,000', '$359,000', 'Est. $682,839', '$478,400', '$639,000', '$510,000', '$209,900', '$939,990', 'Est. $637,372', 'Est. $559,775', 'Est. $756,853', '$310,000', 'Est. $643,036', '$439,500', 'Est. $391,456', '$294,000', '$514,500'], ['3 bds 2 ba 1,253 sqft', '1 bd1 ba 981 sqft', '4 bds 2 ba 1,848 sqft', '4 bds 4 ba 2,406 sqft', '3 bds 2 ba 1,755 sqft', '1 bd1 ba 717 sqft', '4 bds 4 ba 2,460 sqft', '1 bd1 ba 657 sqft', '3 bds 2 ba 3,424 sqft', '3 bds 2 ba 1,384 sqft', '3 bds 2 ba 1,676 sqft', '2 bds 2 ba 990 sqft', '3 bds 3 ba 2,600 sqft', '1 bd1 ba 616 sqft', '2 bds 1 ba 984 sqft', '2 bds 1 ba 980 sqft', '1 bd1 ba 1,697 sqft', '1 bd2 ba 1,077 sqft', '3 bds 2 ba 1,360 sqft', 'Studio1 ba 1,280 sqft', '5 bds 6 ba 4,000 sqft', '3 bds 2 ba 1,462 sqft', '2 bds 2 ba 960 sqft', '2 bds 2 ba 1,377 sqft', '1 bd1 ba 693 sqft', '4 bds 1 ba 1,743 sqft', 'Studio1 ba 1,082 sqft', '1 bd2 ba 1,421 sqft', '2 bds 1 ba 700 sqft', '2 bds 2 ba 900 sqft', '4 bds 3 ba 2,527 sqft', '3 bds 2 ba 1,885 sqft', '3 bds 2 ba 1,298 sqft', '3 bds 1 ba 1,600 sqft', '1 bd1 ba 597 sqft', '3 bds 2 ba 1,120 sqft', 'Studio1 ba 787 sqft', '1 bd1 ba 622 sqft', '7,688 sqft lot', '3 bds 2 ba 1,600 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_11=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_11.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_11 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_11.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_11 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_11.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "\n",
    "print(f\"{buy_address_list_11}, {buy_price_list_11}, {buy_details_list_11}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1521+Locust+Ave+APT+3', '6065+Gundry+Ave', '6259+California+Ave', '1750+E+Ocean+Blvd+UNIT+404', '1720+E+1st+St+APT+1', '488+E+Ocean+Blvd+UNIT+1701', '224+Rivo+Alto+Canal', '2121+Shipway+Ave', '850+E+Ocean+Blvd+APT+607', '5444+Olive+Ave', '228+E+68th+St', '1935+Golden+Ave', '3622+Pacific+Ave', '1360+Orange+Ave', '4199+E+Ransom+St', '429+Magnolia+Ave', '8019+Dorado+Cir', '8034+Dorado+Cir', '5865+E+Mezzanine+Way', '1960+W+Burnett+St', '535+W+4th+St+APT+212', '935+Elm+Ave', '6550+E+Brittain+St', '6841+E+Septimo+St', '5802+E+Gossamer+St', '525+E+Seaside+Way+UNIT+709', '3535+Falcon+Ave', '3829+Hackett+Ave', '1513+E+Broadway', '6425+E+El+Paseo+St', '100+W+5th+St+UNIT+7E', '327+Chestnut+Ave+APT+204', '5585+E+Pacific+Coast+Hwy+UNIT+209', '3113+Atlantic+Ave+UNIT+31', '6700+Gale+Ave', '205+E+Bort+St', '1206+Gladys+Ave', '3400+Gale+Ave', '335+Cedar+Ave+UNIT+402', '2559+Cedar+Ave'], ['Est. $360,753', 'Est. $445,530', 'Est. $531,779', '$529,900', '$4,450,000', '$649,000', '$4,000,000', 'Est. $811,178', '$999,900', 'Est. $467,228', 'Est. $400,120', 'Est. $525,207', 'Est. $1,010,947', 'Est. $496,247', '$1,349,000', '$1,490,000', '$935,990', '$897,990+', 'Est. $755,688', 'Est. $499,031', 'Est. $260,336', '$989,000', 'Est. $749,017', 'Est. $854,077', 'Est. $842,250', '$739,000', '$--', 'Est. $853,941', '$1,350,000', 'Est. $726,814', '$649,000', 'Est. $395,063', '$310,000', '$436,178', 'Est. $493,558', '$432,444', '$2,450,000', 'Est. $508,361', '$309,000', 'Est. $782,688'], ['2 bds 2 ba 1,064 sqft', '2 bds 1 ba 915 sqft', '4 bds 2 ba 1,464 sqft', '1 bd1 ba 632 sqft', '4 bds 3 ba 8,926 sqft', '2 bds 2 ba 960 sqft', '5,619 sqft lot', '4 bds 2 ba 2,209 sqft', '3 bds 3 ba 1,788 sqft', '3 bds 2 ba 1,110 sqft', '2 bds 1 ba 1,144 sqft', '2 bds 2 ba 1,156 sqft', '6 bds 5 ba 3,243 sqft', 'Studio-- ba 924 sqft', '3 bds 3 ba 4,560 sqft', '5 bds 3 ba 4,032 sqft', '4 bds 3 ba 2,527 sqft', '4 bds 4 ba 2,465 sqft', '4 bds 2 ba 1,883 sqft', '3 bds 2 ba 1,188 sqft', '1 bd1 ba 552 sqft', '4 bds 4 ba 3,344 sqft', '4 bds 2 ba 1,903 sqft', '3 bds 2 ba 1,907 sqft', '4 bds 3 ba 2,548 sqft', '2 bds 2 ba 1,399 sqft', '2 bds 1 ba 850 sqft', '5 bds 2 ba 2,510 sqft', '5 bds 5 ba 2,474 sqft', '3 bds 2 ba 1,552 sqft', '1 bd1 ba 1,244 sqft', '2 bds 2 ba 1,010 sqft', '1 bd1 ba 597 sqft', '2 bds 3 ba 1,233 sqft', '3 bds 2 ba 1,466 sqft', '2 bds 1 ba 816 sqft', '2 bds 2 ba 7,680 sqft', '4 bds 2 ba 1,345 sqft', '1 bd1 ba 617 sqft', '4 bds 3 ba 2,449 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_12=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_12.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_12 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_12.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_12 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_12.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "\n",
    "print(f\"{buy_address_list_12}, {buy_price_list_12}, {buy_details_list_12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['315+W+3rd+St+UNIT+605', '1372+Lewis+Ave', '5493+E+29th+St', '27+66th+Pl', '1215+Orizaba+Ave', '1000+E+Ocean+Blvd+UNIT+203', '731+Junipero+Ave', '30+Belmont+Ave', '1371+Granada+Ave', '3408+E+64th+St', '1518+E+3rd+St', '5313+Marina+Pacifica+Dr+S', '1439+Locust+Ave', '5961+E+Walton+St', '3320+E+8th+St', '3595+Santa+Fe+Ave+#+88', '8042+Dorado+Cir', '100+Atlantic+Ave+APT+1115', '349+E+Smith+St', '433+Pine+Ave+UNIT+406', '850+E+Ocean+Blvd+UNIT+405', '477+E+Sunset+St', '5104+Marina+Pacifica+Dr+S', '1467+Obispo+Ave+APT+5', '486+Walnut+Ave', '1187+E+3rd+St+UNIT+211', '841+Gardenia+Ave+APT+305', '57+W+Arbor+St', '2316+Tulane+Ave', '3811+Marber+Ave', '2816+E+56th+St', '411+W+Seaside+Way+UNIT+1901', '1510+Stanley+Ave', '2730+Rodloy+Ave', '1741+Rose+Ave', '1934+Locust+Ave', '1947+Daisy+Ave', '433+Pine+Ave+UNIT+302', '1837+Lime+Ave', '1116+Belmont+Ave+#+A'], ['$649,950', '$849,900', 'Est. $692,934', '$1,775,000', '$1,389,000', '$1,089,000', 'Est. $630,136', '$2,700,000', 'Est. $745,216', 'Est. $531,119', '$7,495,000', '$549,900', 'Est. $435,163', 'Est. $735,871', '$1,200,000', '$524,500', '$1,034,990+', '$299,000', 'Est. $567,308', '$604,900', '$895,000', '$--', '$412,500', 'Est. $257,878', 'Est. $876,524', 'Est. $417,398', 'Est. $256,234', 'Est. $606,058', 'Est. $801,197', 'Est. $690,857', '$--', '$949,000', 'Est. $493,265', 'Est. $503,361', 'Est. $495,811', 'Est. $609,047', '$849,000', '$539,000', 'Est. $508,041', 'Est. $1,056,348'], ['1 bd1 ba 1,284 sqft', '5 bds 3 ba 1,904 sqft', '3 bds 2 ba 1,438 sqft', '3 bds 4 ba 2,463 sqft', '9 bds 9 ba 4,700 sqft', '3 bds 2 ba 1,510 sqft', '2 bds 1 ba 1,162 sqft', '3 bds 2 ba 4,096 sqft', '2 bds 1 ba 1,364 sqft', '4 bds 2 ba 1,551 sqft', '3 bds 2 ba 16,428 sqft', '1 bd2 ba 980 sqft', '3 bds 1 ba 1,344 sqft', '4 bds 2 ba 1,633 sqft', '4 bds 4 ba 2,940 sqft', '3 bds 2 ba 1,600 sqft', '4 bds 4 ba 2,901 sqft', 'Studio1 ba 490 sqft', '4 bds 2 ba 1,816 sqft', '1 bd1 ba 954 sqft', '2 bds 2 ba 1,399 sqft', '1 bd1 ba 500 sqft', 'Studio1 ba 701 sqft', '1 bd1 ba 570 sqft', '5 bds 3 ba 2,189 sqft', '2 bds 2 ba 1,039 sqft', '1 bd1 ba 540 sqft', '3 bds 2 ba 1,585 sqft', '3 bds 2 ba 1,951 sqft', '4 bds 2 ba 1,718 sqft', '3 bds 2 ba 1,406 sqft', '2 bds 2 ba 1,330 sqft', '2 bds 1 ba 863 sqft', '4 bds 2 ba 1,285 sqft', '2 bds 1 ba 752 sqft', '3 bds 2 ba 1,408 sqft', '2 bds 3 ba 1,552 sqft', 'Studio1 ba 1,228 sqft', '3 bds 1 ba 989 sqft', '5 bds 3 ba 2,571 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_13=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_13.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_13 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_13.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_13 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_13.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[10]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "\n",
    "print(f\"{buy_address_list_13}, {buy_price_list_13}, {buy_details_list_13}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3595+Santa+Fe+Ave+#182', '224+E+67th+Way', '394+Coronado+Ave', '3260+Chestnut+Ave', '1380+Bennett+Ave', '5708+Malaga+Pl', '2125+W+29th+St', '2361+Tevis+Ave', '1775+Ohio+Ave+UNIT+207', '3440+Walnut+Ave', '1524+Henderson+Ave', '2063+Atlantic+Ave', '174+E+67th+St', '6541+Walnut+Ave', '0+Parade', '1403+Locust+Ave', '1408+Walnut+Ave', '5501+Lemon+Ave', '1310+E+Ocean+Blvd+UNIT+1005', '5703+E+Belen+St', '1115+E+Artesia+Blvd', '2408+Linden+Ave', '645+Pacific+Ave+UNIT+212', '206+E+68th+St', '8032+Dorado+Cir', '1865+Lemon+Ave', '7135+Eastondale+Ave', '388+E+Ocean+Blvd+UNIT+212', '8016+Dorado+Cir', '30+W+Harcourt+St', '1330+E+Michelson+St', '224+E+67th+Way+#+1', '224+E+67th+Way+#+2', '416+W+Burnett+St+APT+1-4', '1524+E+3rd+St', '645+Chestnut+Ave+APT+315', '3595+Santa+Fe+Ave+#+53', '1310+E+Ocean+Blvd+UNIT+903', '55+W+Arbor+St+#+57', '2320+Delta+Ave'], ['$504,500', '$650,000', '$4,225,000', 'Est. $730,549', 'Est. $630,171', 'Est. $1,173,927', 'Est. $495,917', 'Est. $738,525', 'Est. $387,850', 'Est. $638,221', '$1,298,000', 'Est. $583,042', 'Est. $549,712', 'Est. $457,926', '$300,000', 'Est. $604,723', '$954,900', 'Est. $512,282', '$725,000', 'Est. $663,266', '$335,000', 'Est. $609,258', 'Est. $421,553', '$1,550,000', '$899,990+', '$690,000', 'Est. $504,267', 'Est. $598,161', '$899,990+', 'Est. $534,374', 'Est. $520,484', '$650,000', '$650,000', '$1,100,000', '$3,400,000', 'Est. $387,828', '$514,500', '$699,900', '$747,382', 'Est. $521,233'], ['3 bds 2 ba 1,600 sqft', '5 bds 2 ba 1,926 sqft', '5 bds 4 ba 8,688 sqft', '3 bds 2 ba 1,784 sqft', '2 bds 1 ba 1,017 sqft', '5 bds 3 ba 2,927 sqft', '3 bds 2 ba 1,649 sqft', '3 bds 2 ba 1,645 sqft', '2 bds 2 ba 1,019 sqft', '2 bds 1 ba 1,099 sqft', '4 bds 4 ba 4,636 sqft', '3 bds 2 ba 1,750 sqft', '3 bds 2 ba 1,707 sqft', '2 bds 1 ba 1,088 sqft', '5,431 sqft lot', '2 bds 2 ba 1,457 sqft', '6 bds 4 ba 3,538 sqft', '3 bds 2 ba 1,227 sqft', '1 bd1 ba 990 sqft', '3 bds 1 ba 1,386 sqft', '6,207 sqft lot', '3 bds 2 ba 1,564 sqft', '2 bds 2 ba 988 sqft', '8 bds 6 ba -- sqft', '4 bds 3 ba 2,527 sqft', '6 bds 3 ba 3,504 sqft', '4 bds 2 ba 1,300 sqft', '2 bds 2 ba 1,040 sqft', '4 bds 3 ba 2,527 sqft', '3 bds 2 ba 1,438 sqft', '3 bds 2 ba 1,148 sqft', '5 bds 2 ba 1,926 sqft', '5 bds 2 ba 1,926 sqft', '4 bds 4 ba 2,355 sqft', '5 bds 6 ba 9,044 sqft', '2 bds 2 ba 867 sqft', '3 bds 2 ba 1,600 sqft', '1 bd1 ba 960 sqft', '3 bds 2 ba 1,585 sqft', '2 bds 1 ba 1,386 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_14=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_14.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_14 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_14.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_14 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_14.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "\n",
    "print(f\"{buy_address_list_14}, {buy_price_list_14}, {buy_details_list_14}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['114+W+Market+St', '2528+E+17th+St', '1000+E+Ocean+Blvd+UNIT+306', '1927+Caspian+Ave', '43+E+Plymouth+St', '0+Long+Beach+Blvd', '3322+Elm+Ave', '2240+Delta+Ave', '1415+Locust+Ave', '4910+Oregon+Ave', '6974+Long+Beach+Blvd', '1315+W+21st+St', '6441+Indiana+Ave', '2391+Fashion+Ave', '3166+San+Francisco+Ave', '134+W+Plymouth+St', '1140+E+Ocean+Blvd+UNIT+210', '444+E+Norton+St', '5535+Ackerfield+Ave+UNIT+44', '8015+Dorado+Cir', '3318+Elm+Ave', '206+1/2+E+68th+St', '2017+W+Jeanette+Pl', '6170+Coke+Ave', '1974+Daisy+Ave', '2620+Fashion+Ave', '5825+Jaymills+Ave', '3221+E+Curry+St', '940+Martin+Luther+King+Jr+Ave', '3309+N+Crest+Dr', '2101+E+63rd+St', '1041+E+66th+Way', '51+W+Harcourt+St', '1631+E+10th+St', '3231+E+Janice+St', '1310+E+Ocean+Blvd+UNIT+603', '7062+Olive+Ave', '5462+Atlantic+Ave', '5933+Lemon+Ave', '6460+Brayton+Ave'], [], ['4 bds 4 ba 2,216 sqft', '2 bds 1 ba 808 sqft', '3 bds 2 ba 1,409 sqft', '3 bds 3 ba 3,036 sqft', '4 bds 3 ba 1,738 sqft', '348 sqft lot', '2 bds 2 ba 977 sqft', '3 bds 1 ba 999 sqft', '8 bds 4 ba 3,833 sqft', '4 bds 3 ba 1,800 sqft', '3 bds 2 ba 17,703 sqft', '3 bds 3 ba 1,899 sqft', '3 bds 1 ba 1,321 sqft', '2 bds 1 ba 1,162 sqft', '3 bds 1 ba 996 sqft', '4 bds 2 ba 1,578 sqft', '1 bd1 ba 732 sqft', '3 bds -- ba 1,238 sqft', '1 bd1 ba 671 sqft', '4 bds 3 ba 2,527 sqft', '2 bds 3 ba 979 sqft', '8 bds 6 ba 3,372 sqft', '3 bds 2 ba 1,210 sqft', '3 bds 2 ba 1,219 sqft', '3 bds 1 ba 1,519 sqft', '4 bds 2 ba 2,466 sqft', '2 bds 1 ba 833 sqft', '4 bds 2 ba 1,332 sqft', '2,992 sqft lot', '2 bds 2 ba 1,100 sqft', '2 bds 1 ba 864 sqft', '6 bds 3 ba 2,342 sqft', '3 bds 2 ba 1,474 sqft', '2 bds 3 ba 1,540 sqft', '4 bds 2 ba 1,200 sqft', '1 bd1 ba 960 sqft', '2 bds 1 ba 905 sqft', '4 bds 4 ba 2,926 sqft', '2 bds 2 ba 1,164 sqft', '3 bds 2 ba 1,475 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_15=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_15.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_15 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_14.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_15 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_15.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "        \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[8]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()\n",
    "\n",
    "print(f\"{buy_address_list_15}, {buy_price_list_15}, {buy_details_list_15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['324+W+7th+St', '1133+Ohio+Ave', '435+Daisy+Ave', '2701+Adriatic+Ave', '1940+Henderson+Ave', '6648+Gale+Ave', '1012+E+10th+St', '2514+Adriatic+Ave', '2333+Caspian+Ave', '4935+Locust+Ave', '6568+Gundry+Ave', '1058+E+70th+Way', '3076+Gale+Ave', '401+W+31st+St', '1410+E+60th+St', '6890+Long+Beach+Blvd', '1733+W+29th+St', '2408+And+2410+Linden+Ave', '5828+Falcon+Ave', '2190+W+17th+St', '1081+E+66th+Way', '84+W+Pleasant+St', '774+Obispo+Ave', '1941+Daisy+Ave', '1901+Pacific+Ave', '259+E+Ellis+St', '6761+Delta+Ave', '1232+E+Washington+St', '115+W+4th+St+UNIT+206', '3358+Elm+Ave+#+22', '1020+E+10th+St', '1941+&+1947+Daisy+Ave', '1826+N+Palmer+Ct', '1600+Orizaba+Ave', '6341+Coronado+Ave', '259+E+52nd+St', '5925+Orange+Ave', '8115+Marina+Pacifica+Dr+N', '2135+E+4th+St+APT+302'], ['$1,195,000', '$2,495,000', 'Est. $953,422', 'Est. $546,514', 'Est. $824,839', 'Est. $481,647', '$640,000', 'Est. $512,896', 'Est. $687,612', 'Est. $500,764', 'Est. $539,136', 'Est. $448,040', 'Est. $449,278', 'Est. $618,842', 'Est. $574,698', '$590,000', 'Est. $521,749', '$748,681', 'Est. $460,283', '$800,000', 'Est. $506,706', 'Est. $460,471', '$1,489,000', '$849,000', '$570,000', 'Est. $515,769', 'Est. $411,045', 'Est. $495,972', 'Est. $594,496', 'Est. $376,880', '$640,000', '$849,000', '$--', '$2,800,000', '$589,900', '$369,900', '$475,000', 'Est. $385,335', 'Est. $450,874'], ['1 bd1 ba 2,808 sqft', '2 bds 2 ba 6,120 sqft', '2 bds 4 ba 2,770 sqft', '4 bds 2 ba 1,693 sqft', '4 bds 4 ba 2,732 sqft', '3 bds 1 ba 1,099 sqft', '7,514 sqft lot', '3 bds 2 ba 1,347 sqft', '5 bds 2 ba 2,459 sqft', '2 bds 1 ba 1,242 sqft', '3 bds 1 ba 1,704 sqft', '2 bds 1 ba 900 sqft', '2 bds 1 ba 889 sqft', '3 bds 2 ba 1,191 sqft', '2 bds 2 ba 1,599 sqft', '0.36 acres lot', '3 bds 1 ba 1,683 sqft', '-- bds -- ba -- sqft', '2 bds 1 ba 980 sqft', '9,134 sqft lot', '3 bds 1 ba 1,144 sqft', '2 bds 1 ba 796 sqft', '9 bds 5 ba 4,191 sqft', '2 bds 3 ba 1,552 sqft', '8,150 sqft lot', '4 bds 1 ba 1,670 sqft', '2 bds 1 ba 861 sqft', '2 bds 1 ba 916 sqft', '-- bds 1 ba 1,136 sqft', '2 bds 2 ba 977 sqft', '7,509 sqft lot', '1 bd1 ba -- sqft', 'Studio-- ba 5,882 sqft', 'Studio-- ba 6,543 sqft', '3 bds 2 ba 1,200 sqft', '2 bds 2 ba 650 sqft', '3 bds 2 ba 1,250 sqft', 'Studio-- ba 650 sqft', '2 bds 2 ba 1,111 sqft']\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "buy_address_list_16=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    full_add = result.text\n",
    "    idx = full_add.index(\",\")\n",
    "    api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "    buy_address_list_16.append(api_add)\n",
    "\n",
    "    \n",
    "buy_price_list_16 = []\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-price\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_price_list_16.append(result.text)\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "\n",
    "\n",
    "buy_details_list_16 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        buy_details_list_16.append(result.text.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on {result}\")\n",
    "        \n",
    "\n",
    "print(f\"{buy_address_list_16}, {buy_price_list_16}, {buy_details_list_16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641, 641, 641)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_address_list = buy_address_list_1 + buy_address_list_2 + buy_address_list_3 + buy_address_list_4+buy_address_list_5\\\n",
    "+buy_address_list_6+buy_address_list_7+buy_address_list_8+buy_address_list_9+buy_address_list_10+buy_address_list_11\\\n",
    "+buy_address_list_12+buy_address_list_13+buy_address_list_14+buy_address_list_15+buy_address_list_16\n",
    "\n",
    "buy_price_list=buy_price_list_1+buy_price_list_2+buy_price_list_3+buy_price_list_4+buy_price_list_5+buy_price_list_6\\\n",
    "+buy_price_list_7+buy_price_list_8+buy_price_list_9+buy_price_list_10+buy_price_list_11+buy_price_list_12+buy_price_list_13\\\n",
    "+buy_price_list_14+buy_price_list_15+buy_price_list_16\n",
    "\n",
    "buy_details_list = buy_details_list_1+buy_details_list_2+buy_details_list_3+buy_details_list_4+buy_details_list_5\\\n",
    "+buy_details_list_6+buy_details_list_7+buy_details_list_8+buy_details_list_9+buy_details_list_10+buy_details_list_11\\\n",
    "+buy_details_list_12+buy_details_list_13+buy_details_list_14+buy_details_list_15+buy_details_list_16\n",
    "\n",
    "len(buy_address_list), len(buy_price_list), len(buy_details_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>price</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4208+Tulane+Ave</td>\n",
       "      <td>$1,423,500</td>\n",
       "      <td>5 bds 4 ba 3,850 sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1582+W+31st+St</td>\n",
       "      <td>$649,999</td>\n",
       "      <td>5 bds 3 ba 2,209 sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3615+Faust+Ave</td>\n",
       "      <td>$849,000</td>\n",
       "      <td>3 bds 2 ba 1,664 sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1312+E+Luray+St</td>\n",
       "      <td>$659,000</td>\n",
       "      <td>4 bds 2 ba 1,836 sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5615+Dairy+Ave</td>\n",
       "      <td>$439,000</td>\n",
       "      <td>3 bds 1 ba 956 sqft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           address       price                details\n",
       "0  4208+Tulane+Ave  $1,423,500  5 bds 4 ba 3,850 sqft\n",
       "1   1582+W+31st+St    $649,999  5 bds 3 ba 2,209 sqft\n",
       "2   3615+Faust+Ave    $849,000  3 bds 2 ba 1,664 sqft\n",
       "3  1312+E+Luray+St    $659,000  4 bds 2 ba 1,836 sqft\n",
       "4   5615+Dairy+Ave    $439,000    3 bds 1 ba 956 sqft"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_property_list = pd.DataFrame({\"address\":buy_address_list, \"price\":buy_price_list, \"details\":buy_details_list})\n",
    "buy_property_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_property_list.to_csv(\"Data/buy_property_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grabbing the Rental Address List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)\n",
    "# url = 'https://www.zillow.com/'\n",
    "# browser.visit(url)\n",
    "\n",
    "search_bar_xpath ='//*[@id=\"search-box-input\"]'\n",
    "search_bar = browser.find_by_xpath(search_bar_xpath)[0]\n",
    "\n",
    "search_bar.clear()\n",
    "search_bar.fill('Long Beach, CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button_xpath = '//*[@id=\"search-bar\"]/div/div/form/div/div[1]/label' \n",
    "search_button = browser.find_by_xpath(search_button_xpath)[0] \n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select \"For Rent\"\n",
    "rent_button_xpath = '/html/body/div[9]/div/div[1]/div/div/div/ul/li[2]/button' \n",
    "rent_button = browser.find_by_xpath(rent_button_xpath)\n",
    "rent_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "#Grab the first page of results and store them\n",
    "time.sleep(3)\n",
    "\n",
    "rent_address_1=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_1.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_1 = []\n",
    "counter=0\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_1.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_1 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_1.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_1.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_1), len(rent_price_1), len(rent_details_1))\n",
    "\n",
    "    \n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_2=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_2.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_2 = []\n",
    "counter=0\n",
    "\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_2.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_2 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_2.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_2.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_2), len(rent_price_2), len(rent_details_2))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_3=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_3.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_3 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_3.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_3 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_3.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_3.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_3), len(rent_price_3), len(rent_details_3))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_4=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_4.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_4 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_4.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_4 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_4.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_4.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_4), len(rent_price_4), len(rent_details_4))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[10]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_5=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_5.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_5 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_5.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_5 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_5.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_5.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_5), len(rent_price_5), len(rent_details_5))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_6=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_6.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_6 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_6.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_6 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_6.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_6.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_6), len(rent_price_6), len(rent_details_6))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_7=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_7.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_7 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_7.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_7 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_7.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_7.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_7), len(rent_price_7), len(rent_details_7))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_8=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_8.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_8 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_8.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_8 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_8.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_8.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_8), len(rent_price_8), len(rent_details_8))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_9=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_9.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_9 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_9.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_9 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_9.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_9.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_9), len(rent_price_9), len(rent_details_9))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_10=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_10.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_10 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_10.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_10 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_10.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_10.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_10), len(rent_price_10), len(rent_details_10))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_11=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_11.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_11 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_11.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_11 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_11.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_11.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_11), len(rent_price_11), len(rent_details_11))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_12=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_12.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_12 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_12.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_12 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_12.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_12.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_12), len(rent_price_12), len(rent_details_12))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_13=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_13.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_13 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_13.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_13 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_13.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_13.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_13), len(rent_price_13), len(rent_details_13))\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_14=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_14.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_14 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_14.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_14 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_14.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_14.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_14), len(rent_price_14), len(rent_details_14))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_15=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_15.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_15 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_15.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_15 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_15.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_15.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_15), len(rent_price_15), len(rent_details_15))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_16=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_16.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_16 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_16.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_16 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_16.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_16.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_16), len(rent_price_16), len(rent_details_16))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[11]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_17=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_17.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_17 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_17.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_17 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_17.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_17.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_17), len(rent_price_17), len(rent_details_17))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[10]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_18=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_18.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_18 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_18.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_18 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_18.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_18.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_18), len(rent_price_18), len(rent_details_18))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[9]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_19=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_19.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_19 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_19.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_19 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_19.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_19.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_19), len(rent_price_19), len(rent_details_19))\n",
    "\n",
    "# Click \"Next\" button\n",
    "next_button_xpath = '//*[@id=\"mobile-pagination-root\"]/div/ol/li[8]/a' \n",
    "next_button = browser.find_by_xpath(next_button_xpath)[0]\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "rent_address_20=[]\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results=soup.find_all('h3',class_=\"list-card-addr\")\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        full_add = result.text\n",
    "        idx = full_add.index(\",\")\n",
    "        api_add = full_add[:idx].replace(\" \", \"+\")\n",
    "        rent_address_20.append(api_add)\n",
    "    except:\n",
    "        print(f\"n/a on address {result}\")\n",
    "\n",
    "rent_price_20 = []\n",
    "counter=0\n",
    "results=soup.find_all('div',class_=\"list-card-heading\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        counter += 1\n",
    "        text = result.text\n",
    "        if \"$\" in text:\n",
    "            start_idx = text.index(\"$\")\n",
    "            end_idx = start_idx + 8\n",
    "            price=text[start_idx:end_idx]\n",
    "        else:\n",
    "            price=\"na\"\n",
    "        rent_price_20.append(price)\n",
    "    except:\n",
    "        print(f\"fail scraping price on number {counter}\")\n",
    "\n",
    "\n",
    "rent_details_20 = []\n",
    "\n",
    "results=soup.find_all('ul',class_=\"list-card-details\")\n",
    "\n",
    "for result in results:\n",
    "    try:\n",
    "        details = result.text\n",
    "        if \"$\" in details:\n",
    "            start_idx = details.index(\"$\") + 8\n",
    "            rent_details_20.append(details[8:].replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "        else:\n",
    "            rent_details_20.append(details.replace(\"bds\", \"bds \").replace(\"ba\", \"ba \"))\n",
    "    except:\n",
    "        print(f\"n/a on details {result}\")\n",
    "        \n",
    "\n",
    "print(len(rent_address_20), len(rent_price_20), len(rent_details_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 800)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent_address_list = rent_address_1+rent_address_2+rent_address_3+rent_address_4+rent_address_5+rent_address_6+rent_address_7\\\n",
    "+rent_address_8+rent_address_9+rent_address_10+rent_address_11+rent_address_12+rent_address_13+rent_address_14+rent_address_15\\\n",
    "+rent_address_16+rent_address_17+rent_address_18+rent_address_19+rent_address_20\n",
    "\n",
    "rent_price_list = rent_price_1+rent_price_2+rent_price_3+rent_price_4+rent_price_5+rent_price_6+rent_price_7+rent_price_8\\\n",
    "+rent_price_9+rent_price_10+rent_price_11+rent_price_12+rent_price_13+rent_price_14+rent_price_15+rent_price_16+rent_price_17\\\n",
    "+rent_price_18+rent_price_19+rent_price_20\n",
    "\n",
    "rent_details_list = rent_details_1+rent_details_2+rent_details_3+rent_details_4+rent_details_5+rent_details_6+rent_details_7\\\n",
    "+rent_details_8+rent_details_9+rent_details_10+rent_details_11+rent_details_12+rent_details_13+rent_details_14\\\n",
    "+rent_details_15+rent_details_16+rent_details_17+rent_details_18+rent_details_19+rent_details_20\n",
    "\n",
    "len(rent_address_list), len(rent_price_list), len(rent_details_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>price</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Banner+Circle+Apartments</td>\n",
       "      <td>$1,450+/</td>\n",
       "      <td>1 bd1 ba 630 sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Camden+Harbor+View+|+40+Cedar+Walk</td>\n",
       "      <td>$1,977+</td>\n",
       "      <td>1 bd$2,482+ 2 bds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>E+Allin+St</td>\n",
       "      <td>$1,695/m</td>\n",
       "      <td>1 bd1 ba 649 sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1900+Ocean+Beach+Club+|+1900+E+Ocean+Blvd</td>\n",
       "      <td>$2,000+</td>\n",
       "      <td>Studio$2,575+ 1 bd$3,600+ 2 bds $7,000 3 bds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>120+Corinthian+Walk</td>\n",
       "      <td>$3,800/m</td>\n",
       "      <td>3 bds 1 ba 924 sqft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     address     price  \\\n",
       "0                   Banner+Circle+Apartments  $1,450+/   \n",
       "1         Camden+Harbor+View+|+40+Cedar+Walk  $1,977+    \n",
       "2                                 E+Allin+St  $1,695/m   \n",
       "3  1900+Ocean+Beach+Club+|+1900+E+Ocean+Blvd  $2,000+    \n",
       "4                        120+Corinthian+Walk  $3,800/m   \n",
       "\n",
       "                                         details  \n",
       "0                              1 bd1 ba 630 sqft  \n",
       "1                             1 bd$2,482+ 2 bds   \n",
       "2                              1 bd1 ba 649 sqft  \n",
       "3  Studio$2,575+ 1 bd$3,600+ 2 bds $7,000 3 bds   \n",
       "4                            3 bds 1 ba 924 sqft  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent_property_list = pd.DataFrame({\"address\":rent_address_list, \"price\":rent_price_list, \"details\":rent_details_list})\n",
    "rent_property_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_property_list.to_csv(\"Data/rent_property_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
